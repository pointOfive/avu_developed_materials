{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "M10.3 Tutorial: training_and_deploying_at_scale.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjC8YsDgdTzT"
      },
      "source": [
        "**Chapter 19 – Training and Deploying TensorFlow Models at Scale**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YecNqxDtdTzV"
      },
      "source": [
        "_This notebook contains all the sample code in chapter 19._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA8BEeWcdTzW"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/19_training_and_deploying_at_scale.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_kHIZjZdTzX"
      },
      "source": [
        "# Setup\n",
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20 and TensorFlow ≥2.0.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alQ6tfqwdTzX"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    !echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" > /etc/apt/sources.list.d/tensorflow-serving.list\n",
        "    !curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "    !apt update && apt-get install -y tensorflow-model-server\n",
        "    !pip install -q -U tensorflow-serving-api\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.config.list_physical_devices('GPU'):\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deploy\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUmoImeLdTzb"
      },
      "source": [
        "# Deploying TensorFlow models to TensorFlow Serving (TFS)\n",
        "We will use the REST API or the gRPC API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mouGYRTmdTzc"
      },
      "source": [
        "## Save/Load a `SavedModel`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6IN7_Q2dTzc"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_new = X_test[:3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPYrO7i9dTzf",
        "outputId": "721c54ae-1ccf-46c8-dd45-d4cc8674d3e7"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 2s 40us/sample - loss: 0.7018 - accuracy: 0.8223 - val_loss: 0.3722 - val_accuracy: 0.9022\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 2s 36us/sample - loss: 0.3528 - accuracy: 0.9021 - val_loss: 0.3000 - val_accuracy: 0.9170\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 2s 36us/sample - loss: 0.3032 - accuracy: 0.9150 - val_loss: 0.2659 - val_accuracy: 0.9280\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 2s 37us/sample - loss: 0.2730 - accuracy: 0.9233 - val_loss: 0.2442 - val_accuracy: 0.9342\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 2s 37us/sample - loss: 0.2504 - accuracy: 0.9305 - val_loss: 0.2272 - val_accuracy: 0.9346\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 2s 37us/sample - loss: 0.2319 - accuracy: 0.9353 - val_loss: 0.2104 - val_accuracy: 0.9418\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 2s 37us/sample - loss: 0.2156 - accuracy: 0.9395 - val_loss: 0.1987 - val_accuracy: 0.9484\n",
            "Epoch 8/10\n",
            "55000/55000 [==============================] - 2s 36us/sample - loss: 0.2019 - accuracy: 0.9434 - val_loss: 0.1893 - val_accuracy: 0.9496\n",
            "Epoch 9/10\n",
            "55000/55000 [==============================] - 2s 41us/sample - loss: 0.1898 - accuracy: 0.9471 - val_loss: 0.1765 - val_accuracy: 0.9526\n",
            "Epoch 10/10\n",
            "55000/55000 [==============================] - 2s 39us/sample - loss: 0.1791 - accuracy: 0.9495 - val_loss: 0.1691 - val_accuracy: 0.9550\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x13d74aba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5a2TD6UdTzr",
        "outputId": "58462482-29a4-4709-a72c-85299e3995ab"
      },
      "source": [
        "np.round(model.predict(X_new), 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9-MdU1IdTzv",
        "outputId": "624e7945-97f0-4c72-fa2c-19d8f80a06ff"
      },
      "source": [
        "model_version = \"0001\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'my_mnist_model/0001'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ8r2aYadTz2"
      },
      "source": [
        "!rm -rf {model_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmbkVXbWdTz4"
      },
      "source": [
        "tf.saved_model.save(model, model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKelfb4PdTz7",
        "outputId": "a8fdea97-bb20-4782-87ea-b49c131379c1"
      },
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_mnist_model/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "        assets/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZOw4_3odTz-",
        "outputId": "0c703820-5a96-4344-f73f-e7be5bc3e552"
      },
      "source": [
        "!saved_model_cli show --dir {model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel contains the following tag-sets:\n",
            "serve\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xhjl1DCdT0B",
        "outputId": "edc8557d-6779-4df1-d742-b97d2cf0886c"
      },
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel MetaGraphDef contains SignatureDefs with the following keys:\n",
            "SignatureDef key: \"__saved_model_init_op\"\n",
            "SignatureDef key: \"serving_default\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClyEFJJhdT0F",
        "outputId": "9bfa31b9-70b4-404b-c440-87fdad877b55"
      },
      "source": [
        "!saved_model_cli show --dir {model_path} --tag_set serve \\\n",
        "                      --signature_def serving_default"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['flatten_2_input'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 28, 28, 1)\n",
            "      name: serving_default_flatten_2_input:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['dense_5'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 10)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVQqvZcJdT0J",
        "outputId": "4625eeda-7930-4f87-b345-74b222f4d0a5"
      },
      "source": [
        "!saved_model_cli show --dir {model_path} --all"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['flatten_2_input'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 28, 28, 1)\n",
            "        name: serving_default_flatten_2_input:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['dense_5'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 10)\n",
            "        name: StatefulPartitionedCall:0\n",
            "  Method name is: tensorflow/serving/predict\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvq-zyv7dT0L"
      },
      "source": [
        "Let's write the new instances to a `npy` file so we can pass them easily to our model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFbOS47udT0M"
      },
      "source": [
        "np.save(\"my_mnist_tests.npy\", X_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZBql7UzdT0Q",
        "outputId": "6d173538-3145-448f-948f-cf738f978fd5"
      },
      "source": [
        "input_name = model.input_names[0]\n",
        "input_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'flatten_2_input'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J50cmV7AdT0W"
      },
      "source": [
        "And now let's use `saved_model_cli` to make predictions for the instances we just saved:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWGDuHRSdT0W",
        "outputId": "97310793-2bb9-4d45-d7c2-eee1b2f003f9"
      },
      "source": [
        "!saved_model_cli run --dir {model_path} --tag_set serve \\\n",
        "                     --signature_def serving_default    \\\n",
        "                     --inputs {input_name}=my_mnist_tests.npy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-10 10:56:43.396851: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0610 10:56:43.397369 140735810999168 deprecation.py:323] From /Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py:339: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "W0610 10:56:43.421489 140735810999168 deprecation.py:323] From /Users/ageron/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "Result for output key dense_5:\n",
            "[[1.17575204e-04 1.13160660e-07 5.96997386e-04 2.08104262e-03\n",
            "  2.57820852e-06 6.44166794e-05 2.77263990e-08 9.96703804e-01\n",
            "  3.96052455e-05 3.93810158e-04]\n",
            " [1.22226949e-03 2.92685600e-05 9.86054957e-01 9.63000767e-03\n",
            "  8.81790996e-08 2.88744748e-04 1.58111588e-03 1.12290488e-09\n",
            "  1.19344448e-03 1.09315742e-07]\n",
            " [6.40679718e-05 9.63618696e-01 9.04400647e-03 2.98595289e-03\n",
            "  5.95759891e-04 3.74212675e-03 2.50709383e-03 1.14931818e-02\n",
            "  5.52693009e-03 4.22279176e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYmVgGaFdT0Z",
        "outputId": "7364eba8-4493-4e5a-db75-fb5262d27ce0"
      },
      "source": [
        "np.round([[1.1739199e-04, 1.1239604e-07, 6.0210604e-04, 2.0804715e-03, 2.5779348e-06,\n",
        "           6.4079795e-05, 2.7411186e-08, 9.9669880e-01, 3.9654213e-05, 3.9471846e-04],\n",
        "          [1.2294615e-03, 2.9207937e-05, 9.8599273e-01, 9.6755642e-03, 8.8930705e-08,\n",
        "           2.9156188e-04, 1.5831805e-03, 1.1311053e-09, 1.1980456e-03, 1.1113169e-07],\n",
        "          [6.4066830e-05, 9.6359509e-01, 9.0598064e-03, 2.9872139e-03, 5.9552520e-04,\n",
        "           3.7478798e-03, 2.5074568e-03, 1.1462728e-02, 5.5553433e-03, 4.2495009e-04]], 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8M9SFl9dT0d"
      },
      "source": [
        "## TensorFlow Serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmN0LTAcdT0e"
      },
      "source": [
        "Install [Docker](https://docs.docker.com/install/) if you don't have it already. Then run:\n",
        "\n",
        "```bash\n",
        "docker pull tensorflow/serving\n",
        "\n",
        "export ML_PATH=$HOME/ml # or wherever this project is\n",
        "docker run -it --rm -p 8500:8500 -p 8501:8501 \\\n",
        "   -v \"$ML_PATH/my_mnist_model:/models/my_mnist_model\" \\\n",
        "   -e MODEL_NAME=my_mnist_model \\\n",
        "   tensorflow/serving\n",
        "```\n",
        "Once you are finished using it, press Ctrl-C to shut down the server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjw8VNo0dT0f"
      },
      "source": [
        "Alternatively, if `tensorflow_model_server` is installed (e.g., if you are running this notebook in Colab), then the following 3 cells will start the server:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOeIzTj1dT0k"
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = os.path.split(os.path.abspath(model_path))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UReCR57TdT0o"
      },
      "source": [
        "%%bash --bg\n",
        "nohup tensorflow_model_server \\\n",
        "     --rest_api_port=8501 \\\n",
        "     --model_name=my_mnist_model \\\n",
        "     --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMOZ0RUsdT0q",
        "outputId": "a3b78a70-b9c1-4598-f79e-6c77c205a596"
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-11-06 13:04:12.267136: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2019-11-06 13:04:12.283035: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:202] Restoring SavedModel bundle.\n",
            "2019-11-06 13:04:12.300096: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:151] Running initialization op on SavedModel bundle at path: /content/my_mnist_model/0002\n",
            "2019-11-06 13:04:12.304438: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:311] SavedModel load for tags { serve }; Status: success. Took 39993 microseconds.\n",
            "2019-11-06 13:04:12.304900: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:105] No warmup data file found at /content/my_mnist_model/0002/assets.extra/tf_serving_warmup_requests\n",
            "2019-11-06 13:04:12.305057: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: my_mnist_model version: 2}\n",
            "2019-11-06 13:04:12.306462: I tensorflow_serving/model_servers/server.cc:353] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2019-11-06 13:04:12.307179: I tensorflow_serving/model_servers/server.cc:373] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gzvG1kZdT0t"
      },
      "source": [
        "import json\n",
        "\n",
        "input_data_json = json.dumps({\n",
        "    \"signature_name\": \"serving_default\",\n",
        "    \"instances\": X_new.tolist(),\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQwfbU-edT0v",
        "outputId": "e62cdf06-f12a-4dd5-9591-d16ca8440229"
      },
      "source": [
        "repr(input_data_json)[:1500] + \"...\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\'{\"signature_name\": \"serving_default\", \"instances\": [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.23529411852359772, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705882430076599, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9450980424880981, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.776470...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRtdOpg_dT0z"
      },
      "source": [
        "Now let's use TensorFlow Serving's REST API to make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKdxHIjxdT00"
      },
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status() # raise an exception in case of error\n",
        "response = response.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIe_f7-PdT04",
        "outputId": "6adf72fb-082b-4111-b9d3-02872241401b"
      },
      "source": [
        "response.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQ_xfU05dT07",
        "outputId": "11c9f679-c775-4664-d62a-0b3cb0bde5cd"
      },
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inVQq8x9dT0_"
      },
      "source": [
        "### Using the gRPC API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRUNfAESdT0_"
      },
      "source": [
        "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
        "\n",
        "request = PredictRequest()\n",
        "request.model_spec.name = model_name\n",
        "request.model_spec.signature_name = \"serving_default\"\n",
        "input_name = model.input_names[0]\n",
        "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rPaqFrddT1C"
      },
      "source": [
        "import grpc\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "channel = grpc.insecure_channel('localhost:8500')\n",
        "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "response = predict_service.Predict(request, timeout=10.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FPZbEd6dT1D",
        "outputId": "27979b00-fe3f-4b62-8c4b-617843bc6bd9"
      },
      "source": [
        "response"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "outputs {\n",
              "  key: \"dense_4\"\n",
              "  value {\n",
              "    dtype: DT_FLOAT\n",
              "    tensor_shape {\n",
              "      dim {\n",
              "        size: 3\n",
              "      }\n",
              "      dim {\n",
              "        size: 10\n",
              "      }\n",
              "    }\n",
              "    float_val: 2.0824443708988838e-05\n",
              "    float_val: 1.4913139168015732e-08\n",
              "    float_val: 0.0004813199338968843\n",
              "    float_val: 0.001888890634290874\n",
              "    float_val: 2.682592992186983e-07\n",
              "    float_val: 8.666840585647151e-06\n",
              "    float_val: 1.6853943241024183e-10\n",
              "    float_val: 0.9975269436836243\n",
              "    float_val: 3.833709342870861e-05\n",
              "    float_val: 3.4738284739432856e-05\n",
              "    float_val: 0.00017358684272039682\n",
              "    float_val: 0.0002858016814570874\n",
              "    float_val: 0.9816810488700867\n",
              "    float_val: 0.0157401692122221\n",
              "    float_val: 1.1949770339914068e-10\n",
              "    float_val: 0.00023017563216853887\n",
              "    float_val: 3.078056761296466e-05\n",
              "    float_val: 5.393230750883049e-09\n",
              "    float_val: 0.0018584482604637742\n",
              "    float_val: 1.8884094288296183e-09\n",
              "    float_val: 3.397366526769474e-05\n",
              "    float_val: 0.9835277795791626\n",
              "    float_val: 0.001533020636998117\n",
              "    float_val: 0.0014515116345137358\n",
              "    float_val: 0.00018795969663187861\n",
              "    float_val: 0.0011680654715746641\n",
              "    float_val: 0.0014667459763586521\n",
              "    float_val: 0.006120447069406509\n",
              "    float_val: 0.004315734840929508\n",
              "    float_val: 0.00019466254161670804\n",
              "  }\n",
              "}\n",
              "model_spec {\n",
              "  name: \"my_mnist_model\"\n",
              "  version {\n",
              "    value: 2\n",
              "  }\n",
              "  signature_name: \"serving_default\"\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v718uUBRdT1G"
      },
      "source": [
        "Convert the response to a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9VuRtdHYdT1J",
        "outputId": "c883f078-5527-4ff4-8b77-05d999b62dc5"
      },
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "y_proba = tf.make_ndarray(outputs_proto)\n",
        "y_proba.round(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIDLTOsydT1M"
      },
      "source": [
        "Or to a NumPy array if your client does not include the TensorFlow library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJ2KIWmudT1N",
        "outputId": "c147b1eb-a2e8-4ddd-b2f3-1e1a0339124f"
      },
      "source": [
        "output_name = model.output_names[0]\n",
        "outputs_proto = response.outputs[output_name]\n",
        "shape = [dim.size for dim in outputs_proto.tensor_shape.dim]\n",
        "y_proba = np.array(outputs_proto.float_val).reshape(shape)\n",
        "y_proba.round(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.98, 0.02, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.98, 0.  , 0.  , 0.  , 0.  , 0.  , 0.01, 0.  , 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJq_EZIVdT1P"
      },
      "source": [
        "## Deploying a new model version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6JB1drsjdT1Q",
        "outputId": "3f745673-cd5e-45ce-f1f2-7857702a4a9f"
      },
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(50, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-2),\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "55000/55000 [==============================] - 2s 39us/sample - loss: 0.7035 - accuracy: 0.8060 - val_loss: 0.3445 - val_accuracy: 0.9032\n",
            "Epoch 2/10\n",
            "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3213 - accuracy: 0.9084 - val_loss: 0.2660 - val_accuracy: 0.9252\n",
            "Epoch 3/10\n",
            "55000/55000 [==============================] - 2s 37us/sample - loss: 0.2663 - accuracy: 0.9236 - val_loss: 0.2304 - val_accuracy: 0.9392\n",
            "Epoch 4/10\n",
            "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2331 - accuracy: 0.9331 - val_loss: 0.2069 - val_accuracy: 0.9430\n",
            "Epoch 5/10\n",
            "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2105 - accuracy: 0.9390 - val_loss: 0.1910 - val_accuracy: 0.9446\n",
            "Epoch 6/10\n",
            "55000/55000 [==============================] - 2s 35us/sample - loss: 0.1924 - accuracy: 0.9442 - val_loss: 0.1732 - val_accuracy: 0.9518\n",
            "Epoch 7/10\n",
            "55000/55000 [==============================] - 2s 37us/sample - loss: 0.1771 - accuracy: 0.9489 - val_loss: 0.1679 - val_accuracy: 0.9526\n",
            "Epoch 8/10\n",
            "55000/55000 [==============================] - 2s 37us/sample - loss: 0.1650 - accuracy: 0.9527 - val_loss: 0.1574 - val_accuracy: 0.9546\n",
            "Epoch 9/10\n",
            "55000/55000 [==============================] - 2s 35us/sample - loss: 0.1540 - accuracy: 0.9555 - val_loss: 0.1446 - val_accuracy: 0.9590\n",
            "Epoch 10/10\n",
            "55000/55000 [==============================] - 2s 35us/sample - loss: 0.1448 - accuracy: 0.9583 - val_loss: 0.1414 - val_accuracy: 0.9608\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x12f58f908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHv4x-wrdT1S",
        "outputId": "bfc8ea48-def8-4f95-fa85-b25021421152"
      },
      "source": [
        "model_version = \"0002\"\n",
        "model_name = \"my_mnist_model\"\n",
        "model_path = os.path.join(model_name, model_version)\n",
        "model_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'my_mnist_model/0002'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2kfIkPCdT1Y"
      },
      "source": [
        "tf.saved_model.save(model, model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO8csS2IdT1f",
        "outputId": "adf3467e-bfe6-4c59-d3cf-ae1e3bd080f7"
      },
      "source": [
        "for root, dirs, files in os.walk(model_name):\n",
        "    indent = '    ' * root.count(os.sep)\n",
        "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
        "    for filename in files:\n",
        "        print('{}{}'.format(indent + '    ', filename))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_mnist_model/\n",
            "    0002/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "        assets/\n",
            "    0001/\n",
            "        saved_model.pb\n",
            "        variables/\n",
            "            variables.data-00000-of-00001\n",
            "            variables.index\n",
            "        assets/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHRkCXPodT1h"
      },
      "source": [
        "**Warning**: You may need to wait a minute before the new model is loaded by TensorFlow Serving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQjsThr3dT1h"
      },
      "source": [
        "import requests\n",
        "\n",
        "SERVER_URL = 'http://localhost:8501/v1/models/my_mnist_model:predict'\n",
        "            \n",
        "response = requests.post(SERVER_URL, data=input_data_json)\n",
        "response.raise_for_status()\n",
        "response = response.json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfIFhwTOdT1k",
        "outputId": "8ada2bf0-6f31-4ffc-f35e-0b03ca0e7d65"
      },
      "source": [
        "response.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['predictions'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcsPU-lAdT1r",
        "outputId": "db012f81-a376-447e-ee0b-f46d7a197366"
      },
      "source": [
        "y_proba = np.array(response[\"predictions\"])\n",
        "y_proba.round(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O1PmLwHdT1v"
      },
      "source": [
        "# Deploy the model to Google Cloud AI Platform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J1gDzBJdT1v"
      },
      "source": [
        "Follow the instructions in the book to deploy the model to Google Cloud AI Platform, download the service account's private key and save it to the `my_service_account_private_key.json` in the project directory. Also, update the `project_id`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTusWoePdT1w"
      },
      "source": [
        "project_id = \"onyx-smoke-242003\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ladYe_3sdT10"
      },
      "source": [
        "import googleapiclient.discovery\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_service_account_private_key.json\"\n",
        "model_id = \"my_mnist_model\"\n",
        "model_path = \"projects/{}/models/{}\".format(project_id, model_id)\n",
        "model_path += \"/versions/v0001/\" # if you want to run a specific version\n",
        "ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk66opsOdT12"
      },
      "source": [
        "def predict(X):\n",
        "    input_data_json = {\"signature_name\": \"serving_default\",\n",
        "                       \"instances\": X.tolist()}\n",
        "    request = ml_resource.predict(name=model_path, body=input_data_json)\n",
        "    response = request.execute()\n",
        "    if \"error\" in response:\n",
        "        raise RuntimeError(response[\"error\"])\n",
        "    return np.array([pred[output_name] for pred in response[\"predictions\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80OdFgZTdT17",
        "outputId": "fbfe550a-1248-4b26-e1b6-5d57b16131c2"
      },
      "source": [
        "Y_probas = predict(X_new)\n",
        "np.round(Y_probas, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 1.  , 0.  , 0.  ],\n",
              "       [0.  , 0.  , 0.99, 0.01, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
              "       [0.  , 0.96, 0.01, 0.  , 0.  , 0.  , 0.  , 0.01, 0.01, 0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}